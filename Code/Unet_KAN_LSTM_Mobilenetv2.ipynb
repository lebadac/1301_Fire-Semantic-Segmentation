{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10364119,
          "sourceType": "datasetVersion",
          "datasetId": 6419119
        },
        {
          "sourceId": 10365128,
          "sourceType": "datasetVersion",
          "datasetId": 6419843
        },
        {
          "sourceId": 10537281,
          "sourceType": "datasetVersion",
          "datasetId": 6519895
        },
        {
          "sourceId": 10538115,
          "sourceType": "datasetVersion",
          "datasetId": 6520408
        },
        {
          "sourceId": 10544010,
          "sourceType": "datasetVersion",
          "datasetId": 6523926
        },
        {
          "sourceId": 10548777,
          "sourceType": "datasetVersion",
          "datasetId": 6526836
        },
        {
          "sourceId": 10555791,
          "sourceType": "datasetVersion",
          "datasetId": 6530826
        },
        {
          "sourceId": 10558304,
          "sourceType": "datasetVersion",
          "datasetId": 6532207
        },
        {
          "sourceId": 10559139,
          "sourceType": "datasetVersion",
          "datasetId": 6532793
        },
        {
          "sourceId": 10565491,
          "sourceType": "datasetVersion",
          "datasetId": 6537902
        },
        {
          "sourceId": 10565837,
          "sourceType": "datasetVersion",
          "datasetId": 6538095
        },
        {
          "sourceId": 10568650,
          "sourceType": "datasetVersion",
          "datasetId": 6539836
        },
        {
          "sourceId": 241254,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 206097,
          "modelId": 227852
        }
      ],
      "dockerImageVersionId": 30840,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "z-pokqoVsbk1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Input, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tqdm import tqdm\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T17:55:00.337037Z",
          "iopub.execute_input": "2025-02-14T17:55:00.337335Z",
          "iopub.status.idle": "2025-02-14T17:55:03.961578Z",
          "shell.execute_reply.started": "2025-02-14T17:55:00.337310Z",
          "shell.execute_reply": "2025-02-14T17:55:03.960565Z"
        },
        "id": "LxT7mBNQsbk5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "image_train_val_dir = '/kaggle/input/fire-v11/New_Dataset_v9/train_val/image'\n",
        "label_train_val_dir = '/kaggle/input/fire-v11/New_Dataset_v9/train_val/label'\n",
        "image_test_dir = '/kaggle/input/fire-v11/New_Dataset_v9/test/image'\n",
        "label_test_dir = '/kaggle/input/fire-v11/New_Dataset_v9/test/label'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T17:55:03.965943Z",
          "iopub.execute_input": "2025-02-14T17:55:03.966243Z",
          "iopub.status.idle": "2025-02-14T17:55:03.970357Z",
          "shell.execute_reply.started": "2025-02-14T17:55:03.966218Z",
          "shell.execute_reply": "2025-02-14T17:55:03.969387Z"
        },
        "id": "3Nv9Ifmtsbk5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Size\n",
        "IMG_HEIGHT = 288\n",
        "IMG_WIDTH = 288\n",
        "IMG_CHANNELS = 3"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T17:55:03.971453Z",
          "iopub.execute_input": "2025-02-14T17:55:03.971767Z",
          "iopub.status.idle": "2025-02-14T17:55:03.986730Z",
          "shell.execute_reply.started": "2025-02-14T17:55:03.971737Z",
          "shell.execute_reply": "2025-02-14T17:55:03.985888Z"
        },
        "id": "6UKSkkfBsbk6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Get list of files from image and mask folder\n",
        "image_files = sorted([f for f in os.listdir(image_train_val_dir) if f.endswith('.jpg')])\n",
        "label_files = sorted([f for f in os.listdir(label_train_val_dir) if f.endswith('.png')])\n",
        "\n",
        "# Split data into 60% train, 30% validation, 10% test\n",
        "train_ids, val_ids = train_test_split(image_files, test_size=0.225, random_state=11)\n",
        "# Get list of files from test directory\n",
        "test_ids = sorted([f for f in os.listdir(image_test_dir) if f.endswith('.jpg')])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T17:55:05.449308Z",
          "iopub.execute_input": "2025-02-14T17:55:05.449614Z",
          "iopub.status.idle": "2025-02-14T17:55:05.467255Z",
          "shell.execute_reply.started": "2025-02-14T17:55:05.449590Z",
          "shell.execute_reply": "2025-02-14T17:55:05.466423Z"
        },
        "id": "VxDADnUisbk6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_ids)"
      ],
      "metadata": {
        "trusted": true,
        "id": "sf5PeMAVsbk6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create X_train and Y_train\n",
        "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
        "\n",
        "\n",
        "# Load data into X_train and Y_train\n",
        "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "    # Read image\n",
        "    img = imread(os.path.join(image_train_val_dir, id_))[:, :, :IMG_CHANNELS]\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_train[n] = img\n",
        "\n",
        "    # Read mask\n",
        "    mask_file = id_.replace('.jpg', '_label.png')\n",
        "    mask = imread(os.path.join(label_train_val_dir, mask_file))\n",
        "\n",
        "    # If the mask has 3 color channels, convert it to grayscale\n",
        "    if len(mask.shape) == 3:\n",
        "        mask = rgb2gray(mask)\n",
        "\n",
        "    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    Y_train[n] = mask\n",
        "X_train = X_train / 255.0"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T17:55:07.070012Z",
          "iopub.execute_input": "2025-02-14T17:55:07.070350Z",
          "iopub.status.idle": "2025-02-14T17:59:13.820747Z",
          "shell.execute_reply.started": "2025-02-14T17:55:07.070326Z",
          "shell.execute_reply": "2025-02-14T17:59:13.819989Z"
        },
        "id": "duxFc5BQsbk7",
        "outputId": "048ba5bd-7508-4ef0-f105-fc06278ec7dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 1317/1317 [04:05<00:00,  5.36it/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Loop\n",
        "for n in range(1, 100):  # Từ 1 đến 200\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Display root image\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(X_val[n])  # Hiển thị ảnh gốc\n",
        "    plt.title('Original Image')\n",
        "\n",
        "    # Display binary mask (segmented)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(np.squeeze(Y_val[n]), cmap='gray')\n",
        "    plt.title('Mask (Binary Segmentation)')\n",
        "\n",
        "    # Overlay mask into root image\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(X_val[n])\n",
        "    plt.imshow(np.squeeze(Y_val[n]), cmap='jet', alpha=0.5)\n",
        "    plt.title('Image with Mask Overlay')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # # Pause to view each image, press Enter to continue\n",
        "    # input(f\"Display image number {n}. Press Enter to continue...\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Qtqo8EfOsbk7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create X_val and Y_val\n",
        "X_val = np.zeros((len(val_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_val = np.zeros((len(val_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)  # Giữ định dạng bool cho ground truth\n",
        "\n",
        "# Load data into X_val and Y_val\n",
        "for n, id_ in tqdm(enumerate(val_ids), total=len(val_ids)):\n",
        "    # Read image\n",
        "    img = imread(os.path.join(image_train_val_dir, id_))[:, :, :IMG_CHANNELS]\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_val[n] = img\n",
        "\n",
        "    # Read mask\n",
        "    mask_file = id_.replace('.jpg', '_label.png')\n",
        "    mask = imread(os.path.join(label_train_val_dir, mask_file))\n",
        "\n",
        "    # If the mask has 3 color channels, convert it to grayscale\n",
        "    if len(mask.shape) == 3:\n",
        "        mask = rgb2gray(mask)\n",
        "\n",
        "    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    Y_val[n] = mask\n",
        "\n",
        "# Chuẩn hóa X_val (ảnh đầu vào)\n",
        "X_val = X_val / 255.0\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T17:59:13.821786Z",
          "iopub.execute_input": "2025-02-14T17:59:13.822086Z",
          "iopub.status.idle": "2025-02-14T18:00:38.443085Z",
          "shell.execute_reply.started": "2025-02-14T17:59:13.822062Z",
          "shell.execute_reply": "2025-02-14T18:00:38.442276Z"
        },
        "id": "bveO8MuZsbk8",
        "outputId": "5435123f-0afc-4465-c53d-088241273a2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 383/383 [01:24<00:00,  4.54it/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create X_test and Y_test\n",
        "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)  # Thay np.bool bằng bool\n",
        "\n",
        "# Load data into X_test and Y_test\n",
        "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "    # Read image\n",
        "    img = imread(os.path.join(image_test_dir, id_))[:, :, :IMG_CHANNELS]\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_test[n] = img\n",
        "\n",
        "    # Read mask\n",
        "    mask_file = id_.replace('.jpg', '_label.png')\n",
        "    mask = imread(os.path.join(label_test_dir, mask_file))\n",
        "\n",
        "    # Nếu mask có 3 kênh màu, chuyển sang grayscale\n",
        "    if len(mask.shape) == 3:\n",
        "        mask = rgb2gray(mask)\n",
        "\n",
        "    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    mask = np.expand_dims(mask, axis=-1)  # Thêm chiều cho mask\n",
        "    Y_test[n] = mask\n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T18:00:38.444676Z",
          "iopub.execute_input": "2025-02-14T18:00:38.445019Z",
          "iopub.status.idle": "2025-02-14T18:01:16.271770Z",
          "shell.execute_reply.started": "2025-02-14T18:00:38.444987Z",
          "shell.execute_reply": "2025-02-14T18:01:16.270330Z"
        },
        "id": "TdTiXHOwsbk8",
        "outputId": "48cd1843-7952-4dca-de66-37c2c355589d"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 226/226 [00:37<00:00,  6.00it/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL"
      ],
      "metadata": {
        "id": "hOy3nfYisbk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##UNET"
      ],
      "metadata": {
        "id": "4IlUnGgYsbk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_model(input_shape):\n",
        "    \"\"\"\n",
        "    Builds a U-Net model for image segmentation.\n",
        "\n",
        "    Input: input_shape (tuple): Shape of the input image (height, width, channels).\n",
        "\n",
        "    Output: Compiled U-Net model.\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Contracting path (Encoder)\n",
        "    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    c5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Expanding path (Decoder)\n",
        "    u6 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1])\n",
        "    c9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    c9 = layers.Dropout(0.5)(c9)  # Move Dropout inside main decoder path\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "input_shape = (288, 288, 3)\n",
        "model = unet_model(input_shape)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T18:03:06.190991Z",
          "iopub.execute_input": "2025-02-14T18:03:06.191321Z",
          "iopub.status.idle": "2025-02-14T18:03:07.773957Z",
          "shell.execute_reply.started": "2025-02-14T18:03:06.191297Z",
          "shell.execute_reply": "2025-02-14T18:03:07.773275Z"
        },
        "id": "WTU3QEO7sbk-",
        "outputId": "872e20b0-bfd8-457d-f394-6fb10ddbc370"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m896\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m9,248\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m524,544\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                           │                        │                │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m1,179,904\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m131,200\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m295,040\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m32,832\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m8,224\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m18,464\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m9,248\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m33\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                           │                        │                │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,760,097\u001b[0m (29.60 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,760,097</span> (29.60 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,760,097\u001b[0m (29.60 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,760,097</span> (29.60 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SWIN_UNET"
      ],
      "metadata": {
        "id": "w05TA1kWsbk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Patch Partition: Chia ảnh thành các patch\n",
        "class PatchPartition(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(PatchPartition, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        height = tf.shape(inputs)[1]\n",
        "        width = tf.shape(inputs)[2]\n",
        "        channels = inputs.shape[-1]\n",
        "\n",
        "        # Sử dụng tf.image.extract_patches để chia ảnh thành các patch kích thước patch_size x patch_size\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=inputs,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding='VALID'\n",
        "        )\n",
        "\n",
        "        # Reshape lại thành định dạng (batch_size, height // patch_size, width // patch_size, patch_size * patch_size * channels)\n",
        "        patches = tf.reshape(patches, (batch_size, height // self.patch_size, width // self.patch_size, self.patch_size * self.patch_size * channels))\n",
        "\n",
        "        return patches\n",
        "\n",
        "# Linear Embedding: Nhúng các patch vào không gian tuyến tính\n",
        "class LinearEmbedding(layers.Layer):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(LinearEmbedding, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.proj = layers.Dense(embed_dim)  # Sử dụng Dense để giảm chiều về đúng kích thước\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.proj(inputs)  # Chuyển inputs thông qua Dense để giảm số chiều\n",
        "\n",
        "class SwinTransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, window_size, mlp_ratio=4, qkv_bias=True, dropout=0.):\n",
        "        super(SwinTransformerBlock, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.window_size = window_size\n",
        "        self.mlp_ratio = mlp_ratio\n",
        "\n",
        "        self.norm1 = layers.LayerNormalization()\n",
        "        self.attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.norm2 = layers.LayerNormalization()\n",
        "\n",
        "        # Đảm bảo rằng đầu ra của MLP phải cùng kích thước với đầu vào để cộng với `shortcut`\n",
        "        self.mlp = tf.keras.Sequential([\n",
        "            layers.Dense(embed_dim * mlp_ratio, activation='relu'),  # Lớp MLP ẩn\n",
        "            layers.Dense(embed_dim)  # Đầu ra phải có kích thước giống với đầu vào\n",
        "        ])\n",
        "\n",
        "        # Conv2D để đảm bảo rằng số kênh của shortcut và mlp_output khớp nhau\n",
        "        self.proj = layers.Conv2D(embed_dim, kernel_size=1)\n",
        "\n",
        "    def call(self, x):\n",
        "        shortcut = x  # Lưu đầu vào ban đầu để cộng với đầu ra (skip connection)\n",
        "        x = self.norm1(x)\n",
        "        x = self.attn(x, x)  # Self-attention\n",
        "        x = x + shortcut  # Skip connection\n",
        "\n",
        "        shortcut = x  # Cập nhật shortcut cho MLP\n",
        "        x = self.norm2(x)\n",
        "        mlp_output = self.mlp(x)\n",
        "\n",
        "        # Điều chỉnh số lượng kênh của shortcut nếu cần thiết\n",
        "        shortcut = self.proj(shortcut)\n",
        "        x = mlp_output + shortcut  # Skip connection cho MLP\n",
        "\n",
        "        return x\n",
        "\n",
        "# Patch Merging: Giảm kích thước không gian\n",
        "class PatchMerging(layers.Layer):\n",
        "    def __init__(self, output_dim):\n",
        "        super(PatchMerging, self).__init__()\n",
        "        self.conv = layers.Conv2D(output_dim, kernel_size=2, strides=2)\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "# Patch Expanding: Tăng kích thước không gian\n",
        "class PatchExpanding(layers.Layer):\n",
        "    def __init__(self, output_dim, scale_factor=2):\n",
        "        super(PatchExpanding, self).__init__()\n",
        "        self.conv = layers.Conv2D(output_dim, kernel_size=1)\n",
        "        self.scale_factor = scale_factor\n",
        "\n",
        "    def call(self, x):\n",
        "        x = layers.UpSampling2D(size=(self.scale_factor, self.scale_factor))(x)\n",
        "        return self.conv(x)\n",
        "\n",
        "# Linear Projection: Chuyển đổi thành số kênh mong muốn\n",
        "class LinearProjection(layers.Layer):\n",
        "    def __init__(self, output_dim):\n",
        "        super(LinearProjection, self).__init__()\n",
        "        self.conv = layers.Conv2D(output_dim, kernel_size=1)\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.conv(x)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Nvfp4zcSsbk-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Xây dựng mô hình Swin U-Net với các giá trị C điều chỉnh\n",
        "def swin_unet(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Patch Partition và Linear Embedding\n",
        "    x = PatchPartition(patch_size=4)(inputs)\n",
        "    x = LinearEmbedding(embed_dim=3)(x)  # `C=3`\n",
        "\n",
        "    # Encoder\n",
        "    x1 = SwinTransformerBlock(embed_dim=3, num_heads=1, window_size=4)(x)\n",
        "    x1 = SwinTransformerBlock(embed_dim=3, num_heads=1, window_size=4)(x1)\n",
        "\n",
        "    x2 = PatchMerging(output_dim=6)(x1)  # `C=6`\n",
        "    x2 = SwinTransformerBlock(embed_dim=6, num_heads=2, window_size=4)(x2)\n",
        "    x2 = SwinTransformerBlock(embed_dim=6, num_heads=2, window_size=4)(x2)\n",
        "\n",
        "    x3 = PatchMerging(output_dim=12)(x2)  # `C=12`\n",
        "    x3 = SwinTransformerBlock(embed_dim=12, num_heads=4, window_size=4)(x3)\n",
        "    x3 = SwinTransformerBlock(embed_dim=12, num_heads=4, window_size=4)(x3)\n",
        "\n",
        "    x4 = PatchMerging(output_dim=24)(x3)  # `C=24`\n",
        "    x4 = SwinTransformerBlock(embed_dim=24, num_heads=8, window_size=4)(x4)\n",
        "    x4 = SwinTransformerBlock(embed_dim=24, num_heads=8, window_size=4)(x4)\n",
        "\n",
        "    # Decoder\n",
        "    x = PatchExpanding(output_dim=12)(x4)  # `C=12`\n",
        "    x = layers.Concatenate()([x, x3])\n",
        "    x = SwinTransformerBlock(embed_dim=12, num_heads=4, window_size=4)(x)\n",
        "    x = SwinTransformerBlock(embed_dim=12, num_heads=4, window_size=4)(x)\n",
        "\n",
        "    x = PatchExpanding(output_dim=6)(x)  # `C=6`\n",
        "    x = layers.Concatenate()([x, x2])\n",
        "    x = SwinTransformerBlock(embed_dim=6, num_heads=2, window_size=4)(x)\n",
        "    x = SwinTransformerBlock(embed_dim=6, num_heads=2, window_size=4)(x)\n",
        "\n",
        "    x = PatchExpanding(output_dim=3)(x)  # `C=3`\n",
        "    x = layers.Concatenate()([x, x1])\n",
        "    x = SwinTransformerBlock(embed_dim=3, num_heads=1, window_size=4)(x)\n",
        "    x = SwinTransformerBlock(embed_dim=3, num_heads=1, window_size=4)(x)\n",
        "\n",
        "    x = PatchExpanding(output_dim=3, scale_factor=4)(x)  # Trở về WxHx3\n",
        "\n",
        "    outputs = layers.Conv2D(num_classes, kernel_size=(1, 1), activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "model = swin_unet(input_shape=(288, 288, 3), num_classes=1)\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "O1GSHHuusbk-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##U_KAN"
      ],
      "metadata": {
        "id": "n9g2G5bIsbk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "import tensorflow as tf\n",
        "\n",
        "class KANLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    Custom KAN layer implementing learnable activation functions.\n",
        "\n",
        "    Input:\n",
        "        - inputs: Tensor of shape (batch_size, input_dim)\n",
        "\n",
        "    Output:\n",
        "        - Transformed tensor of shape (batch_size, output_dim)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(KANLayer, self).__init__()\n",
        "        # Initialize learnable activation functions as weights\n",
        "        self.activation_funcs = self.add_weight(\n",
        "            shape=(output_dim, input_dim),\n",
        "            initializer=\"he_normal\",  # He Normal initializer for better convergence\n",
        "            trainable=True,\n",
        "            name=\"activation_funcs\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply learnable activation functions element-wise\n",
        "        return tf.tensordot(inputs, self.activation_funcs, axes=1)\n",
        "\n",
        "def tokenized_kan_block(inputs, token_dim, kan_layers=2):\n",
        "    \"\"\"\n",
        "    Implements the Tok-KAN block by flattening inputs, applying KAN, and returning reshaped outputs.\n",
        "    \"\"\"\n",
        "    # Tokenization\n",
        "    tokens = layers.Reshape((-1, inputs.shape[-1]))(inputs)  # Flatten spatial dimensions into tokens\n",
        "    tokens = layers.Dense(token_dim, activation='relu')(tokens)  # Map to token_dim\n",
        "\n",
        "    # Apply KAN layers\n",
        "    for _ in range(kan_layers):\n",
        "        processed_tokens = KANLayer(token_dim, token_dim)(tokens)  # Use the custom KANLayer\n",
        "        processed_tokens = layers.LayerNormalization()(processed_tokens)\n",
        "        tokens = layers.Add()([processed_tokens, tokens])  # Residual connection\n",
        "\n",
        "    # Reshape back to feature map dimensions\n",
        "    return layers.Reshape(inputs.shape[1:])(tokens)\n",
        "\n",
        "def unet_kan(input_shape, kan_dim=128, num_kan_layers=2):\n",
        "    \"\"\"\n",
        "    Builds the U-KAN model following the paper's architecture.\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Contracting path\n",
        "    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    # Bottleneck: Tokenized KAN Block\n",
        "    kan_block_output = tokenized_kan_block(p4, kan_dim, num_kan_layers)\n",
        "\n",
        "    # Expanding path\n",
        "    u1 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(kan_block_output)\n",
        "    u1 = layers.concatenate([u1, c4])\n",
        "    u1 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u1)\n",
        "\n",
        "    u2 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(u1)\n",
        "    u2 = layers.concatenate([u2, c3])\n",
        "    u2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u2)\n",
        "\n",
        "    u3 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(u2)\n",
        "    u3 = layers.concatenate([u3, c2])\n",
        "    u3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u3)\n",
        "\n",
        "    u4 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(u3)\n",
        "    u4 = layers.concatenate([u4, c1])\n",
        "    u4 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u4)\n",
        "\n",
        "    u4 = layers.Dropout(0.5)(u4)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(u4)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "# Instantiate the model\n",
        "input_shape = (288, 288, 3)\n",
        "model = unet_kan(input_shape, kan_dim=256, num_kan_layers=2)\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "OEMz7-8Hsbk-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##U_KAN_LSTM"
      ],
      "metadata": {
        "id": "TkNgpAiBsbk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "import tensorflow as tf\n",
        "\n",
        "class KANLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    Custom KAN layer implementing learnable activation functions.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(KANLayer, self).__init__()\n",
        "        self.activation_funcs = self.add_weight(\n",
        "            shape=(output_dim, input_dim),\n",
        "            initializer=\"he_normal\",\n",
        "            trainable=True,\n",
        "            name=\"activation_funcs\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.tensordot(inputs, self.activation_funcs, axes=1)\n",
        "\n",
        "def tokenized_kan_block(inputs, token_dim, kan_layers=2):\n",
        "    \"\"\"\n",
        "    Tokenized KAN Block with LSTM for feature transformation.\n",
        "    \"\"\"\n",
        "    tokens = layers.Reshape((-1, inputs.shape[-1]))(inputs)\n",
        "    tokens = layers.Dense(token_dim, activation='relu')(tokens)\n",
        "\n",
        "    processed_tokens = KANLayer(token_dim, token_dim)(tokens)\n",
        "    processed_tokens = layers.LayerNormalization()(processed_tokens)\n",
        "\n",
        "    projected_inputs = layers.Conv2D(token_dim, (1, 1), activation='relu', padding='same')(inputs)\n",
        "    lstm_input = layers.Reshape((1, inputs.shape[1], inputs.shape[2], token_dim))(projected_inputs)\n",
        "\n",
        "    lstm_output = layers.ConvLSTM2D(256, (3, 3), activation='relu', padding='same', return_sequences=False)(lstm_input)\n",
        "    lstm_output = layers.Reshape((-1, token_dim))(lstm_output)\n",
        "\n",
        "    tokens = layers.Add()([processed_tokens, lstm_output])\n",
        "    processed_tokens = KANLayer(token_dim, token_dim)(tokens)\n",
        "    processed_tokens = layers.LayerNormalization()(processed_tokens)\n",
        "\n",
        "    reshaped_output = layers.Reshape((inputs.shape[1], inputs.shape[2], token_dim))(processed_tokens)\n",
        "    return reshaped_output\n",
        "\n",
        "def u_kan_lstm(input_shape, kan_dim=128, num_kan_layers=2):\n",
        "    \"\"\"\n",
        "    Builds the U-KAN model.\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    kan_block_output = tokenized_kan_block(p4, kan_dim, num_kan_layers)\n",
        "\n",
        "    u1 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(kan_block_output)\n",
        "    u1 = layers.concatenate([u1, c4])\n",
        "    u1 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u1)\n",
        "\n",
        "    u2 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(u1)\n",
        "    u2 = layers.concatenate([u2, c3])\n",
        "    u2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u2)\n",
        "\n",
        "    u3 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(u2)\n",
        "    u3 = layers.concatenate([u3, c2])\n",
        "    u3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u3)\n",
        "\n",
        "    u4 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(u3)\n",
        "    u4 = layers.concatenate([u4, c1])\n",
        "    u4 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u4)\n",
        "    u4 = layers.Dropout(0.5)(u4)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(u4)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "input_shape = (288, 288, 3)\n",
        "model = u_kan_lstm(input_shape, kan_dim=256, num_kan_layers=2)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "IhqacZctsbk_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##K_UNET_LSTM_Mobilenetv2"
      ],
      "metadata": {
        "id": "ykDdg2IUsbk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "import tensorflow as tf\n",
        "\n",
        "class KANLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    Custom KAN layer implementing learnable activation functions.\n",
        "\n",
        "    Input:\n",
        "        - inputs: Tensor of shape (batch_size, input_dim)\n",
        "\n",
        "    Output:\n",
        "        - Transformed tensor of shape (batch_size, output_dim)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(KANLayer, self).__init__()\n",
        "        # Initialize learnable activation functions as weights\n",
        "        self.activation_funcs = self.add_weight(\n",
        "            shape=(output_dim, input_dim),\n",
        "            initializer=\"he_normal\",  # He Normal initializer for better convergence\n",
        "            trainable=True,\n",
        "            name=\"activation_funcs\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply learnable activation functions element-wise\n",
        "        return tf.tensordot(inputs, self.activation_funcs, axes=1)\n",
        "\n",
        "def tokenized_kan_block(inputs, token_dim, kan_layers=2):\n",
        "    \"\"\"\n",
        "    Tokenized KAN Block with LSTM for feature transformation.\n",
        "\n",
        "    Input:\n",
        "        - inputs: Tensor of shape (batch_size, height, width, channels)\n",
        "        - token_dim: Dimension of token embeddings\n",
        "        - kan_layers: Number of KAN layers\n",
        "\n",
        "    Output:\n",
        "        - Tensor of shape (batch_size, height, width, token_dim)\n",
        "    \"\"\"\n",
        "    # Reshape the input to create tokenized patches\n",
        "    tokens = layers.Reshape((-1, inputs.shape[-1]))(inputs)\n",
        "    tokens = layers.Dense(token_dim, activation='relu')(tokens)  # Linear projection\n",
        "\n",
        "    # First KANLayer\n",
        "    processed_tokens = KANLayer(token_dim, token_dim)(tokens)\n",
        "    processed_tokens = layers.LayerNormalization()(processed_tokens)\n",
        "\n",
        "    # Project inputs to match LSTM input dimensions\n",
        "    projected_inputs = layers.Conv2D(token_dim, (1, 1), activation='relu', padding='same')(inputs)\n",
        "    lstm_input = layers.Reshape((1, inputs.shape[1], inputs.shape[2], token_dim))(projected_inputs)\n",
        "\n",
        "    # LSTM Layer\n",
        "    lstm_output = layers.ConvLSTM2D(256, (3, 3), activation='relu', padding='same', return_sequences=False)(lstm_input)\n",
        "    lstm_output = layers.Reshape((-1, token_dim))(lstm_output)  # Reshape to match tokens\n",
        "\n",
        "    # Combine the outputs of first KANLayer and LSTM\n",
        "    tokens = layers.Add()([processed_tokens, lstm_output])\n",
        "\n",
        "    # Second KANLayer\n",
        "    processed_tokens = KANLayer(token_dim, token_dim)(tokens)\n",
        "    processed_tokens = layers.LayerNormalization()(processed_tokens)\n",
        "\n",
        "    # Final reshape to match the bottleneck shape for subsequent layers\n",
        "    # Use Conv2DTranspose to ensure shape compatibility with skip connections\n",
        "    reshaped_output = layers.Reshape((inputs.shape[1], inputs.shape[2], token_dim))(processed_tokens)\n",
        "\n",
        "    return reshaped_output\n",
        "\n",
        "def u_kan_lstm_mobilenetv2(input_shape, kan_dim=128, num_kan_layers=2):\n",
        "    \"\"\"\n",
        "    U-Net with KAN and LSTM using MobileNetV2 as the backbone.\n",
        "\n",
        "    Input:\n",
        "        - input_shape: Tuple representing the input image dimensions (height, width, channels)\n",
        "        - kan_dim: Dimension of KAN block embeddings\n",
        "        - num_kan_layers: Number of KAN layers in the bottleneck\n",
        "\n",
        "    Output:\n",
        "        - Tensor of shape (batch_size, height, width, 1) representing the segmentation mask\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Pre-trained model for the contracting path\n",
        "    base_model = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=input_shape,\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "    base_model.trainable = False  # Freeze base model layers\n",
        "\n",
        "    c1 = base_model.get_layer('block_1_expand_relu').output\n",
        "    c2 = base_model.get_layer('block_3_expand_relu').output\n",
        "    c3 = base_model.get_layer('block_6_expand_relu').output\n",
        "    c4 = base_model.get_layer('block_13_expand_relu').output\n",
        "\n",
        "    # Bottleneck: Tokenized KAN Block with LSTM\n",
        "    bottleneck = tokenized_kan_block(c4, kan_dim, num_kan_layers)\n",
        "\n",
        "    # Expanding path\n",
        "    u1 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bottleneck)\n",
        "\n",
        "    # Adjust c4 to match u1\n",
        "    c4_resized = layers.Conv2DTranspose(576, (2, 2), strides=(2, 2), padding='same')(c4)\n",
        "    u1 = layers.concatenate([u1, c4_resized])\n",
        "    u1 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u1)\n",
        "\n",
        "    u2 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(u1)\n",
        "\n",
        "    # Adjust c3 to match u2\n",
        "    c3_resized = layers.Conv2DTranspose(192, (2, 2), strides=(2, 2), padding='same')(c3)\n",
        "    u2 = layers.concatenate([u2, c3_resized])\n",
        "    u2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u2)\n",
        "\n",
        "    u3 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(u2)\n",
        "\n",
        "    # Adjust c2 to match u3\n",
        "    c2_resized = layers.Conv2DTranspose(96, (2, 2), strides=(2, 2), padding='same')(c2)\n",
        "    u3 = layers.concatenate([u3, c2_resized])\n",
        "    u3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u3)\n",
        "\n",
        "    u4 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(u3)\n",
        "\n",
        "    # Adjust c1 to match u4\n",
        "    c1_resized = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c1)\n",
        "    u4 = layers.concatenate([u4, c1_resized])\n",
        "    u4 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u4)\n",
        "\n",
        "    u4 = layers.Dropout(0.5)(u4)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(u4)\n",
        "\n",
        "    # Assemble the model\n",
        "    model = models.Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Instantiate the model\n",
        "input_shape = (288, 288, 3)  # RGB image of size 288x288\n",
        "model = u_kan_lstm_mobilenetv2(input_shape, kan_dim=256, num_kan_layers=2)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ue_6i3vcsbk_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRAIN MODEL"
      ],
      "metadata": {
        "id": "gDq2dNgisbk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LOSS (BINARY CATEGORY) + ACCURARY"
      ],
      "metadata": {
        "id": "9L-jy8a_sbk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# Set seed for reproducibility\n",
        "SEED = 50\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Define parameters\n",
        "INITIAL_LEARNING_RATE = 0.001\n",
        "MIN_LEARNING_RATE = 0.0001\n",
        "BETA_1 = 0.9\n",
        "BETA_2 = 0.999\n",
        "BATCH_SIZE = 8\n",
        "DROPOUT_RATE = 0.1\n",
        "MAX_EPOCHS = 100\n",
        "EARLY_STOPPING_PATIENCE = 15\n",
        "\n",
        "# Khai báo optimizer Adam với các tham số tùy chỉnh\n",
        "adam_optimizer = Adam(learning_rate=INITIAL_LEARNING_RATE, beta_1=BETA_1, beta_2=BETA_2)\n",
        "\n",
        "# Compile model với optimizer đã tuỳ chỉnh\n",
        "model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=10,\n",
        "    min_lr=MIN_LEARNING_RATE,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=EARLY_STOPPING_PATIENCE,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Prepare dataset with shuffle and fixed seed\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "dataset_train = dataset_train.shuffle(buffer_size=1024, seed=SEED).batch(BATCH_SIZE)\n",
        "\n",
        "dataset_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
        "dataset_val = dataset_val.batch(BATCH_SIZE)\n",
        "\n",
        "# Then fit the model\n",
        "results = model.fit(\n",
        "    dataset_train,\n",
        "    validation_data=dataset_val,\n",
        "    epochs=MAX_EPOCHS,\n",
        "    callbacks=[reduce_lr, early_stopping]\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "PGxcTIgEsbk_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LOSS (BINARY CATEGORY + DICE) + IOU CLASS 1"
      ],
      "metadata": {
        "id": "tVq1IzAbsbk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import BinaryIoU\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Set seed for reproducibility\n",
        "SEED = 11\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Parameters\n",
        "INITIAL_LEARNING_RATE = 0.001\n",
        "MIN_LEARNING_RATE = 1e-6\n",
        "BETA_1 = 0.9\n",
        "BETA_2 = 0.999\n",
        "BATCH_SIZE = 32\n",
        "MAX_EPOCHS = 100\n",
        "EARLY_STOPPING_PATIENCE = 15\n",
        "num_classes = 2\n",
        "\n",
        "# Define custom loss: BCE + Dice\n",
        "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return 1 - (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "    dice = dice_loss(y_true, y_pred)\n",
        "    return bce + dice\n",
        "\n",
        "# Compile the model\n",
        "adam_optimizer = Adam(\n",
        "    learning_rate=INITIAL_LEARNING_RATE,\n",
        "    beta_1=BETA_1,\n",
        "    beta_2=BETA_2\n",
        ")\n",
        "model.compile(\n",
        "    optimizer=adam_optimizer,\n",
        "    loss=bce_dice_loss,\n",
        "    metrics=[BinaryIoU(threshold=0.5, name='Binary_IoU')]\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=10,\n",
        "    min_lr=MIN_LEARNING_RATE,\n",
        "    verbose=1,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=EARLY_STOPPING_PATIENCE,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "# Evaluate and print metrics after each epoch\n",
        "class EvaluateAndPrintMetrics(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data):\n",
        "        super().__init__()\n",
        "        self.validation_data = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs is None:\n",
        "            logs = {}\n",
        "        val_loss = logs.get('val_loss')\n",
        "        val_binary_iou = logs.get('val_Binary_IoU')\n",
        "        print(f\"Epoch {epoch+1}:\")\n",
        "        print(f\"   Validation Loss: {val_loss:.4f}\")\n",
        "        print(f\"   Validation Binary IoU: {val_binary_iou:.4f}\")\n",
        "\n",
        "# Create callback\n",
        "eval_callback = EvaluateAndPrintMetrics(validation_data=(X_val, Y_val))\n",
        "\n",
        "# Prepare dataset with shuffle and fixed seed\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "dataset_train = dataset_train.shuffle(buffer_size=1024, seed=SEED).batch(BATCH_SIZE)\n",
        "\n",
        "dataset_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
        "dataset_val = dataset_val.batch(BATCH_SIZE)\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    dataset_train,\n",
        "    validation_data=dataset_val,\n",
        "    epochs=MAX_EPOCHS,\n",
        "    callbacks=[reduce_lr, early_stopping, eval_callback]\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T18:03:33.951008Z",
          "iopub.execute_input": "2025-02-14T18:03:33.951336Z",
          "iopub.status.idle": "2025-02-14T18:37:31.684737Z",
          "shell.execute_reply.started": "2025-02-14T18:03:33.951315Z",
          "shell.execute_reply": "2025-02-14T18:37:31.683625Z"
        },
        "id": "BNr1gOn7sblA",
        "outputId": "c73e658e-b7b0-4389-bcd4-cdc9376ae3a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - Binary_IoU: 0.4200 - loss: 1.2711   Epoch 1:\n   Validation Loss: 0.8902\n   Validation Binary IoU: 0.5187\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 3s/step - Binary_IoU: 0.4194 - loss: 1.2673 - val_Binary_IoU: 0.5187 - val_loss: 0.8902 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756ms/step - Binary_IoU: 0.5045 - loss: 0.8965Epoch 2:\n   Validation Loss: 0.8426\n   Validation Binary IoU: 0.5590\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 822ms/step - Binary_IoU: 0.5025 - loss: 0.8968 - val_Binary_IoU: 0.5590 - val_loss: 0.8426 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756ms/step - Binary_IoU: 0.5454 - loss: 0.8056Epoch 3:\n   Validation Loss: 0.8517\n   Validation Binary IoU: 0.5504\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 822ms/step - Binary_IoU: 0.5439 - loss: 0.8060 - val_Binary_IoU: 0.5504 - val_loss: 0.8517 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - Binary_IoU: 0.5397 - loss: 0.8105Epoch 4:\n   Validation Loss: 0.7788\n   Validation Binary IoU: 0.5582\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 819ms/step - Binary_IoU: 0.5387 - loss: 0.8098 - val_Binary_IoU: 0.5582 - val_loss: 0.7788 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.5484 - loss: 0.7531Epoch 5:\n   Validation Loss: 0.6055\n   Validation Binary IoU: 0.6480\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.5474 - loss: 0.7523 - val_Binary_IoU: 0.6480 - val_loss: 0.6055 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - Binary_IoU: 0.6305 - loss: 0.6474Epoch 6:\n   Validation Loss: 0.5901\n   Validation Binary IoU: 0.6657\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 813ms/step - Binary_IoU: 0.6292 - loss: 0.6475 - val_Binary_IoU: 0.6657 - val_loss: 0.5901 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.6439 - loss: 0.6014Epoch 7:\n   Validation Loss: 0.5092\n   Validation Binary IoU: 0.6997\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 813ms/step - Binary_IoU: 0.6431 - loss: 0.6006 - val_Binary_IoU: 0.6997 - val_loss: 0.5092 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.6704 - loss: 0.5486Epoch 8:\n   Validation Loss: 0.5281\n   Validation Binary IoU: 0.6877\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 813ms/step - Binary_IoU: 0.6690 - loss: 0.5494 - val_Binary_IoU: 0.6877 - val_loss: 0.5281 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.6838 - loss: 0.5229Epoch 9:\n   Validation Loss: 0.4733\n   Validation Binary IoU: 0.7201\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.6829 - loss: 0.5231 - val_Binary_IoU: 0.7201 - val_loss: 0.4733 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - Binary_IoU: 0.6673 - loss: 0.5557Epoch 10:\n   Validation Loss: 0.4927\n   Validation Binary IoU: 0.7098\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.6665 - loss: 0.5553 - val_Binary_IoU: 0.7098 - val_loss: 0.4927 - learning_rate: 0.0010\nEpoch 11/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - Binary_IoU: 0.6785 - loss: 0.5290Epoch 11:\n   Validation Loss: 0.4629\n   Validation Binary IoU: 0.7262\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 813ms/step - Binary_IoU: 0.6775 - loss: 0.5289 - val_Binary_IoU: 0.7262 - val_loss: 0.4629 - learning_rate: 0.0010\nEpoch 12/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - Binary_IoU: 0.6971 - loss: 0.5106Epoch 12:\n   Validation Loss: 0.4915\n   Validation Binary IoU: 0.7155\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 811ms/step - Binary_IoU: 0.6963 - loss: 0.5106 - val_Binary_IoU: 0.7155 - val_loss: 0.4915 - learning_rate: 0.0010\nEpoch 13/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - Binary_IoU: 0.7008 - loss: 0.4871Epoch 13:\n   Validation Loss: 0.5388\n   Validation Binary IoU: 0.6797\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 813ms/step - Binary_IoU: 0.6999 - loss: 0.4869 - val_Binary_IoU: 0.6797 - val_loss: 0.5388 - learning_rate: 0.0010\nEpoch 14/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - Binary_IoU: 0.6998 - loss: 0.4938Epoch 14:\n   Validation Loss: 0.5142\n   Validation Binary IoU: 0.7002\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.6993 - loss: 0.4931 - val_Binary_IoU: 0.7002 - val_loss: 0.5142 - learning_rate: 0.0010\nEpoch 15/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.7191 - loss: 0.4667Epoch 15:\n   Validation Loss: 0.4315\n   Validation Binary IoU: 0.7388\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.7186 - loss: 0.4659 - val_Binary_IoU: 0.7388 - val_loss: 0.4315 - learning_rate: 0.0010\nEpoch 16/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - Binary_IoU: 0.7404 - loss: 0.4154Epoch 16:\n   Validation Loss: 0.4053\n   Validation Binary IoU: 0.7505\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.7394 - loss: 0.4157 - val_Binary_IoU: 0.7505 - val_loss: 0.4053 - learning_rate: 0.0010\nEpoch 17/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - Binary_IoU: 0.7408 - loss: 0.4151Epoch 17:\n   Validation Loss: 0.4194\n   Validation Binary IoU: 0.7466\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 810ms/step - Binary_IoU: 0.7399 - loss: 0.4152 - val_Binary_IoU: 0.7466 - val_loss: 0.4194 - learning_rate: 0.0010\nEpoch 18/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.7356 - loss: 0.4271Epoch 18:\n   Validation Loss: 0.4615\n   Validation Binary IoU: 0.7212\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 813ms/step - Binary_IoU: 0.7349 - loss: 0.4269 - val_Binary_IoU: 0.7212 - val_loss: 0.4615 - learning_rate: 0.0010\nEpoch 19/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.7561 - loss: 0.3890Epoch 19:\n   Validation Loss: 0.4789\n   Validation Binary IoU: 0.7139\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.7550 - loss: 0.3896 - val_Binary_IoU: 0.7139 - val_loss: 0.4789 - learning_rate: 0.0010\nEpoch 20/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.7536 - loss: 0.3820Epoch 20:\n   Validation Loss: 0.4469\n   Validation Binary IoU: 0.7287\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.7528 - loss: 0.3821 - val_Binary_IoU: 0.7287 - val_loss: 0.4469 - learning_rate: 0.0010\nEpoch 21/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751ms/step - Binary_IoU: 0.7622 - loss: 0.3814Epoch 21:\n   Validation Loss: 0.4161\n   Validation Binary IoU: 0.7475\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 815ms/step - Binary_IoU: 0.7616 - loss: 0.3811 - val_Binary_IoU: 0.7475 - val_loss: 0.4161 - learning_rate: 0.0010\nEpoch 22/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - Binary_IoU: 0.7807 - loss: 0.3452Epoch 22:\n   Validation Loss: 0.4869\n   Validation Binary IoU: 0.7269\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 812ms/step - Binary_IoU: 0.7800 - loss: 0.3452 - val_Binary_IoU: 0.7269 - val_loss: 0.4869 - learning_rate: 0.0010\nEpoch 23/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.7614 - loss: 0.3886Epoch 23:\n   Validation Loss: 0.3613\n   Validation Binary IoU: 0.7760\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.7608 - loss: 0.3882 - val_Binary_IoU: 0.7760 - val_loss: 0.3613 - learning_rate: 0.0010\nEpoch 24/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - Binary_IoU: 0.7818 - loss: 0.3434Epoch 24:\n   Validation Loss: 0.4079\n   Validation Binary IoU: 0.7515\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 813ms/step - Binary_IoU: 0.7809 - loss: 0.3438 - val_Binary_IoU: 0.7515 - val_loss: 0.4079 - learning_rate: 0.0010\nEpoch 25/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - Binary_IoU: 0.7825 - loss: 0.3501Epoch 25:\n   Validation Loss: 0.4012\n   Validation Binary IoU: 0.7581\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 815ms/step - Binary_IoU: 0.7818 - loss: 0.3500 - val_Binary_IoU: 0.7581 - val_loss: 0.4012 - learning_rate: 0.0010\nEpoch 26/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.7410 - loss: 0.4170Epoch 26:\n   Validation Loss: 0.4092\n   Validation Binary IoU: 0.7511\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.7407 - loss: 0.4161 - val_Binary_IoU: 0.7511 - val_loss: 0.4092 - learning_rate: 0.0010\nEpoch 27/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.7883 - loss: 0.3410Epoch 27:\n   Validation Loss: 0.3247\n   Validation Binary IoU: 0.7944\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.7879 - loss: 0.3405 - val_Binary_IoU: 0.7944 - val_loss: 0.3247 - learning_rate: 0.0010\nEpoch 28/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - Binary_IoU: 0.8128 - loss: 0.2907Epoch 28:\n   Validation Loss: 0.3514\n   Validation Binary IoU: 0.7827\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 812ms/step - Binary_IoU: 0.8120 - loss: 0.2911 - val_Binary_IoU: 0.7827 - val_loss: 0.3514 - learning_rate: 0.0010\nEpoch 29/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - Binary_IoU: 0.7989 - loss: 0.3076Epoch 29:\n   Validation Loss: 0.3128\n   Validation Binary IoU: 0.8004\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 813ms/step - Binary_IoU: 0.7983 - loss: 0.3076 - val_Binary_IoU: 0.8004 - val_loss: 0.3128 - learning_rate: 0.0010\nEpoch 30/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.8154 - loss: 0.2794Epoch 30:\n   Validation Loss: 0.3962\n   Validation Binary IoU: 0.7591\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.8148 - loss: 0.2796 - val_Binary_IoU: 0.7591 - val_loss: 0.3962 - learning_rate: 0.0010\nEpoch 31/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.8295 - loss: 0.2601Epoch 31:\n   Validation Loss: 0.3369\n   Validation Binary IoU: 0.7993\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 813ms/step - Binary_IoU: 0.8290 - loss: 0.2603 - val_Binary_IoU: 0.7993 - val_loss: 0.3369 - learning_rate: 0.0010\nEpoch 32/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - Binary_IoU: 0.8161 - loss: 0.2960Epoch 32:\n   Validation Loss: 0.3530\n   Validation Binary IoU: 0.7849\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 811ms/step - Binary_IoU: 0.8159 - loss: 0.2953 - val_Binary_IoU: 0.7849 - val_loss: 0.3530 - learning_rate: 0.0010\nEpoch 33/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.8208 - loss: 0.2736Epoch 33:\n   Validation Loss: 0.2983\n   Validation Binary IoU: 0.8124\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 813ms/step - Binary_IoU: 0.8203 - loss: 0.2736 - val_Binary_IoU: 0.8124 - val_loss: 0.2983 - learning_rate: 0.0010\nEpoch 34/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - Binary_IoU: 0.8420 - loss: 0.2387Epoch 34:\n   Validation Loss: 0.3458\n   Validation Binary IoU: 0.7888\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.8415 - loss: 0.2389 - val_Binary_IoU: 0.7888 - val_loss: 0.3458 - learning_rate: 0.0010\nEpoch 35/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - Binary_IoU: 0.8544 - loss: 0.2226Epoch 35:\n   Validation Loss: 0.3106\n   Validation Binary IoU: 0.8028\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.8539 - loss: 0.2227 - val_Binary_IoU: 0.8028 - val_loss: 0.3106 - learning_rate: 0.0010\nEpoch 36/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.8538 - loss: 0.2237Epoch 36:\n   Validation Loss: 0.3338\n   Validation Binary IoU: 0.7968\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 813ms/step - Binary_IoU: 0.8536 - loss: 0.2233 - val_Binary_IoU: 0.7968 - val_loss: 0.3338 - learning_rate: 0.0010\nEpoch 37/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.8628 - loss: 0.2018Epoch 37:\n   Validation Loss: 0.3377\n   Validation Binary IoU: 0.7963\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.8625 - loss: 0.2018 - val_Binary_IoU: 0.7963 - val_loss: 0.3377 - learning_rate: 0.0010\nEpoch 38/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.8727 - loss: 0.1899Epoch 38:\n   Validation Loss: 0.3471\n   Validation Binary IoU: 0.7863\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.8723 - loss: 0.1899 - val_Binary_IoU: 0.7863 - val_loss: 0.3471 - learning_rate: 0.0010\nEpoch 39/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - Binary_IoU: 0.8704 - loss: 0.1940Epoch 39:\n   Validation Loss: 0.3118\n   Validation Binary IoU: 0.8042\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 813ms/step - Binary_IoU: 0.8700 - loss: 0.1938 - val_Binary_IoU: 0.8042 - val_loss: 0.3118 - learning_rate: 0.0010\nEpoch 40/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.8819 - loss: 0.1726Epoch 40:\n   Validation Loss: 0.2933\n   Validation Binary IoU: 0.8133\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.8815 - loss: 0.1726 - val_Binary_IoU: 0.8133 - val_loss: 0.2933 - learning_rate: 0.0010\nEpoch 41/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - Binary_IoU: 0.8791 - loss: 0.1776Epoch 41:\n   Validation Loss: 0.3022\n   Validation Binary IoU: 0.8094\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 815ms/step - Binary_IoU: 0.8789 - loss: 0.1774 - val_Binary_IoU: 0.8094 - val_loss: 0.3022 - learning_rate: 0.0010\nEpoch 42/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - Binary_IoU: 0.8912 - loss: 0.1654Epoch 42:\n   Validation Loss: 0.3057\n   Validation Binary IoU: 0.8095\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 816ms/step - Binary_IoU: 0.8910 - loss: 0.1653 - val_Binary_IoU: 0.8095 - val_loss: 0.3057 - learning_rate: 0.0010\nEpoch 43/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.8925 - loss: 0.1577Epoch 43:\n   Validation Loss: 0.3221\n   Validation Binary IoU: 0.8067\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.8921 - loss: 0.1578 - val_Binary_IoU: 0.8067 - val_loss: 0.3221 - learning_rate: 0.0010\nEpoch 44/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.8974 - loss: 0.1486Epoch 44:\n   Validation Loss: 0.3169\n   Validation Binary IoU: 0.8040\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 815ms/step - Binary_IoU: 0.8971 - loss: 0.1486 - val_Binary_IoU: 0.8040 - val_loss: 0.3169 - learning_rate: 0.0010\nEpoch 45/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - Binary_IoU: 0.9089 - loss: 0.1306Epoch 45:\n   Validation Loss: 0.3330\n   Validation Binary IoU: 0.8069\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.9086 - loss: 0.1306 - val_Binary_IoU: 0.8069 - val_loss: 0.3330 - learning_rate: 0.0010\nEpoch 46/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - Binary_IoU: 0.9166 - loss: 0.1202Epoch 46:\n   Validation Loss: 0.2967\n   Validation Binary IoU: 0.8180\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 814ms/step - Binary_IoU: 0.9163 - loss: 0.1202 - val_Binary_IoU: 0.8180 - val_loss: 0.2967 - learning_rate: 0.0010\nEpoch 47/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751ms/step - Binary_IoU: 0.9220 - loss: 0.1143Epoch 47:\n   Validation Loss: 0.3111\n   Validation Binary IoU: 0.8123\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 816ms/step - Binary_IoU: 0.9218 - loss: 0.1142 - val_Binary_IoU: 0.8123 - val_loss: 0.3111 - learning_rate: 0.0010\nEpoch 48/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - Binary_IoU: 0.9299 - loss: 0.1002Epoch 48:\n   Validation Loss: 0.3191\n   Validation Binary IoU: 0.8143\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 817ms/step - Binary_IoU: 0.9296 - loss: 0.1004 - val_Binary_IoU: 0.8143 - val_loss: 0.3191 - learning_rate: 0.0010\nEpoch 49/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - Binary_IoU: 0.9288 - loss: 0.1029Epoch 49:\n   Validation Loss: 0.3224\n   Validation Binary IoU: 0.8157\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 815ms/step - Binary_IoU: 0.9286 - loss: 0.1029 - val_Binary_IoU: 0.8157 - val_loss: 0.3224 - learning_rate: 0.0010\nEpoch 50/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751ms/step - Binary_IoU: 0.9304 - loss: 0.0994\nEpoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\nEpoch 50:\n   Validation Loss: 0.3185\n   Validation Binary IoU: 0.8140\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 816ms/step - Binary_IoU: 0.9303 - loss: 0.0994 - val_Binary_IoU: 0.8140 - val_loss: 0.3185 - learning_rate: 0.0010\nEpoch 51/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - Binary_IoU: 0.9418 - loss: 0.0816Epoch 51:\n   Validation Loss: 0.3108\n   Validation Binary IoU: 0.8171\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 816ms/step - Binary_IoU: 0.9415 - loss: 0.0818 - val_Binary_IoU: 0.8171 - val_loss: 0.3108 - learning_rate: 5.0000e-04\nEpoch 52/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751ms/step - Binary_IoU: 0.9408 - loss: 0.0836Epoch 52:\n   Validation Loss: 0.3204\n   Validation Binary IoU: 0.8161\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 816ms/step - Binary_IoU: 0.9406 - loss: 0.0836 - val_Binary_IoU: 0.8161 - val_loss: 0.3204 - learning_rate: 5.0000e-04\nEpoch 53/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - Binary_IoU: 0.9472 - loss: 0.0759Epoch 53:\n   Validation Loss: 0.3284\n   Validation Binary IoU: 0.8157\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 812ms/step - Binary_IoU: 0.9470 - loss: 0.0760 - val_Binary_IoU: 0.8157 - val_loss: 0.3284 - learning_rate: 5.0000e-04\nEpoch 54/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - Binary_IoU: 0.9493 - loss: 0.0716Epoch 54:\n   Validation Loss: 0.3320\n   Validation Binary IoU: 0.8146\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 812ms/step - Binary_IoU: 0.9491 - loss: 0.0717 - val_Binary_IoU: 0.8146 - val_loss: 0.3320 - learning_rate: 5.0000e-04\nEpoch 55/100\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - Binary_IoU: 0.9524 - loss: 0.0678Epoch 55:\n   Validation Loss: 0.3256\n   Validation Binary IoU: 0.8155\n\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 813ms/step - Binary_IoU: 0.9521 - loss: 0.0679 - val_Binary_IoU: 0.8155 - val_loss: 0.3256 - learning_rate: 5.0000e-04\nEpoch 55: early stopping\nRestoring model weights from the end of the best epoch: 40.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save model"
      ],
      "metadata": {
        "id": "OCX6zIhTuM86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"okila.h5\")\n",
        "print(\"Model has been saved to my_model.h5\")\n"
      ],
      "metadata": {
        "id": "4-vkVoz0uKQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import model"
      ],
      "metadata": {
        "id": "0Kd0TdjbuGqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define your custom layer\n",
        "class KANLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    Custom KAN layer implementing learnable activation functions.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, **kwargs):\n",
        "        super(KANLayer, self).__init__(**kwargs)  # Ensure to accept other arguments like 'trainable'\n",
        "        # Initialize learnable activation functions as weights\n",
        "        self.activation_funcs = self.add_weight(\n",
        "            shape=(output_dim, input_dim),\n",
        "            initializer=\"he_normal\",  # He Normal initializer for better convergence\n",
        "            trainable=True,\n",
        "            name=\"activation_funcs\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply learnable activation functions element-wise\n",
        "        return tf.tensordot(inputs, self.activation_funcs, axes=1)\n",
        "\n",
        "# Load the saved model with the custom layer and without compiling\n",
        "model = load_model(\n",
        "    \"/kaggle/input/mobilenet_unet_lstm_kan/tensorflow2/default/1/okila.h5\",\n",
        "    custom_objects={\"KANLayer\": KANLayer},\n",
        "    compile=False  # Avoid compilation during model loading\n",
        ")\n",
        "\n",
        "print(\"Model has been loaded successfully.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "0BbyB-emsblA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EVALUATE MODEL"
      ],
      "metadata": {
        "id": "8-WsV2keuTik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "# Dice Coefficient function\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    intersection = np.sum(y_true * y_pred)\n",
        "    return (2. * intersection + 1e-6) / (np.sum(y_true) + np.sum(y_pred) + 1e-6)\n",
        "\n",
        "# Predict labels for test set\n",
        "start_time = time.time()  # Start to calculate time\n",
        "Y_pred = model.predict(X_test)\n",
        "end_time = time.time()  # End to calculate time\n",
        "\n",
        "# Average time per image\n",
        "num_images = X_test.shape[0]\n",
        "average_time_per_image = (end_time - start_time) / num_images\n",
        "\n",
        "# Convert predictions to binary labels\n",
        "Y_pred = (Y_pred > 0.5).astype(np.uint8)\n",
        "\n",
        "# Initialize metrics\n",
        "num_classes = 2  # Example: background and fire\n",
        "iou_scores = []\n",
        "dice_scores = []\n",
        "pixel_accuracy = 0\n",
        "mean_accuracy = 0\n",
        "freq_weighted_iou = 0\n",
        "total_pixels = np.prod(Y_test.shape)\n",
        "\n",
        "for i in range(num_classes):\n",
        "    y_true_class = (Y_test == i).astype(np.uint8)\n",
        "    y_pred_class = (Y_pred == i).astype(np.uint8)\n",
        "\n",
        "    # Calculate Intersection and Union\n",
        "    intersection = np.sum(y_true_class * y_pred_class)\n",
        "    union = np.sum(y_true_class) + np.sum(y_pred_class) - intersection\n",
        "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
        "    iou_scores.append(iou)\n",
        "\n",
        "    # Calculate Dice Coefficient\n",
        "    dice = dice_coefficient(y_true_class, y_pred_class)\n",
        "    dice_scores.append(dice)\n",
        "\n",
        "    # Pixel Accuracy for class\n",
        "    pixel_accuracy += intersection\n",
        "    mean_accuracy += intersection / (np.sum(y_true_class) + 1e-6)\n",
        "\n",
        "    # FWIoU Component\n",
        "    freq_weighted_iou += (np.sum(y_true_class) / total_pixels) * iou\n",
        "\n",
        "# Normalize metrics\n",
        "pixel_accuracy /= total_pixels\n",
        "mean_accuracy /= num_classes\n",
        "\n",
        "# Calculate Mean IoU and Mean Dice\n",
        "mean_iou = np.mean(iou_scores)\n",
        "mean_dice = np.mean(dice_scores)\n",
        "\n",
        "# Print results\n",
        "print(f\"Pixel Accuracy: {pixel_accuracy:.4f}\")\n",
        "print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
        "print(f\"Mean IoU: {mean_iou:.4f}\")\n",
        "print(f\"Frequency Weighted IoU: {freq_weighted_iou:.4f}\")\n",
        "print(f\"Mean Dice Coefficient: {mean_dice:.4f}\")\n",
        "print(f\"Average time per image: {average_time_per_image:.6f} seconds\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T18:37:44.482675Z",
          "iopub.execute_input": "2025-02-14T18:37:44.483067Z",
          "iopub.status.idle": "2025-02-14T18:37:52.969389Z",
          "shell.execute_reply.started": "2025-02-14T18:37:44.483037Z",
          "shell.execute_reply": "2025-02-14T18:37:52.968618Z"
        },
        "id": "Ci0WkmsWsblA",
        "outputId": "42b01201-3da4-45aa-9b23-8201b62fa919"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 941ms/step\nPixel Accuracy: 0.9667\nMean Accuracy: 0.8468\nMean IoU: 0.7762\nFrequency Weighted IoU: 0.9398\nMean Dice Coefficient: 0.8611\nAverage time per image: 0.035933 seconds\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "# Dice Coefficient function\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    intersection = np.sum(y_true * y_pred)\n",
        "    return (2. * intersection + 1e-6) / (np.sum(y_true) + np.sum(y_pred) + 1e-6)\n",
        "\n",
        "# Predict labels for test set\n",
        "start_time = time.time()  # Start to calculate time\n",
        "Y_pred = model.predict(X_test)\n",
        "end_time = time.time()  # End to calculate time\n",
        "\n",
        "# Average time per image\n",
        "num_images = X_test.shape[0]\n",
        "average_time_per_image = (end_time - start_time) / num_images\n",
        "\n",
        "# Convert to binary label\n",
        "Y_pred = (Y_pred > 0.5).astype(np.uint8)\n",
        "\n",
        "# Number of layers: 2 (background and fire)\n",
        "num_classes = 2\n",
        "\n",
        "# Initialize Mean IoU metric\n",
        "iou_scores = []\n",
        "dice_scores = []\n",
        "\n",
        "for i in range(num_classes):\n",
        "    y_true_class = (Y_test == i).astype(np.uint8)\n",
        "    y_pred_class = (Y_pred == i).astype(np.uint8)\n",
        "\n",
        "    # Tính IoU cho từng lớp\n",
        "    intersection = np.sum(y_true_class * y_pred_class)\n",
        "    union = np.sum(y_true_class) + np.sum(y_pred_class) - intersection\n",
        "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
        "    iou_scores.append(iou)\n",
        "\n",
        "    # Tính Dice Coefficient cho từng lớp\n",
        "    dice = dice_coefficient(y_true_class, y_pred_class)\n",
        "    dice_scores.append(dice)\n",
        "\n",
        "# Calculate Mean IoU and Mean Dice\n",
        "mean_iou = np.mean(iou_scores)\n",
        "mean_dice = np.mean(dice_scores)\n",
        "\n",
        "# Print results\n",
        "for i in range(num_classes):\n",
        "    print(f\"Class {i}: IoU = {iou_scores[i]:.4f}, Dice = {dice_scores[i]:.4f}\")\n",
        "print(f\"Mean IoU: {mean_iou:.4f}\")\n",
        "print(f\"Mean Dice Coefficient: {mean_dice:.4f}\")\n",
        "print(f\"Average time per image: {average_time_per_image:.6f} seconds\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "L2arPlVNsblA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Print image"
      ],
      "metadata": {
        "id": "MHyoO6RKsblA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# một số ảnh và mask\n",
        "num_images = 250# Số lượng ảnh muốn hiển thị\n",
        "for i in range(num_images):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.imshow(X_test[i])\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(\"True Mask\")\n",
        "    plt.imshow(Y_test[i].squeeze(), cmap='gray')  # Squeeze để loại bỏ chiều không cần thiết\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"Predicted Mask\")\n",
        "    plt.imshow(Y_pred[i].squeeze(), cmap='gray')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "wP20lOkcsblA"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}